{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b7e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard is a powerful tool for visualizing and debugging machine learning models, \n",
    "# particularly in TensorFlow and Keras. It allows us to monitor key metrics, such as loss and accuracy,\n",
    "# track training progress in real-time, and analyze the performance of various model components \n",
    "# throughout the training process\n",
    "\n",
    "# Let's start by importing the California Housing dataset from Scikit-Learn\n",
    "from sklearn.datasets import fetch_california_housing  # Load the California housing dataset\n",
    "from sklearn.model_selection import train_test_split    # Tool to split data into train/validation/test sets\n",
    "from sklearn.preprocessing import StandardScaler        # Tool to scale features to standard normal distribution\n",
    "\n",
    "# Load the dataset (features and target)\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "\n",
    "# Further split training data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "# Standardize the features: zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)      # Fit on training data and transform it\n",
    "X_valid = scaler.transform(X_valid)          # Use the same transformation on validation data\n",
    "X_test = scaler.transform(X_test)            # Use the same transformation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940392d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system, specifically to create directories and handle paths.\n",
    "import os\n",
    "\n",
    "# Define the root directory where the log files will be stored.\n",
    "# 'os.curdir' represents the current working directory. 'my_logs' is the subdirectory where logs will be saved.\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "# Define a function to generate a unique directory path for each run.\n",
    "# This function creates a directory name based on the current date and time to ensure unique names for each experiment.\n",
    "def get_run_logdir():\n",
    "    # Import the time module to work with time-based information.\n",
    "    import time\n",
    "    \n",
    "    # Get the current time and format it as a string (e.g., 'run_2025_04_22-12_34_56').\n",
    "    # This helps in creating a unique run ID for every new experiment.\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    \n",
    "    # Return the full path to the log directory for the current run. This will be under the root_logdir.\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Call the get_run_logdir function to create the log directory path for the current run.\n",
    "# This will create a new subdirectory under 'my_logs' with a timestamped name.\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda85ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - loss: 0.5196 - val_loss: 0.4562\n",
      "Epoch 2/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - loss: 0.4411 - val_loss: 0.4593\n",
      "Epoch 3/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - loss: 0.4649 - val_loss: 0.3973\n",
      "Epoch 4/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.3792 - val_loss: 0.4472\n",
      "Epoch 5/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.3584 - val_loss: 0.3633\n",
      "Epoch 6/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 0.3715 - val_loss: 0.4291\n",
      "Epoch 7/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 0.3797 - val_loss: 0.3684\n",
      "Epoch 8/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - loss: 0.3620 - val_loss: 0.4367\n",
      "Epoch 9/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.3470 - val_loss: 0.3926\n",
      "Epoch 10/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - loss: 0.5422 - val_loss: 0.3761\n",
      "Epoch 11/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - loss: 0.3502 - val_loss: 0.3545\n",
      "Epoch 12/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - loss: 0.3490 - val_loss: 0.4307\n",
      "Epoch 13/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 0.3664 - val_loss: 0.7572\n",
      "Epoch 14/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 44ms/step - loss: 0.3771 - val_loss: 0.6465\n",
      "Epoch 15/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - loss: 0.4179 - val_loss: 0.5307\n",
      "Epoch 16/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.4467 - val_loss: 0.4294\n",
      "Epoch 17/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - loss: 0.3224 - val_loss: 0.4478\n",
      "Epoch 18/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - loss: 0.5004 - val_loss: 0.4118\n",
      "Epoch 19/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - loss: 0.3142 - val_loss: 0.3151\n",
      "Epoch 20/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - loss: 0.2993 - val_loss: 0.4885\n",
      "Epoch 21/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - loss: 0.3056 - val_loss: 0.4877\n",
      "Epoch 22/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 43ms/step - loss: 0.5692 - val_loss: 0.3400\n",
      "Epoch 23/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 44ms/step - loss: 0.4559 - val_loss: 0.3334\n",
      "Epoch 24/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 44ms/step - loss: 0.4115 - val_loss: 0.4800\n",
      "Epoch 25/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - loss: 0.4308 - val_loss: 0.3747\n",
      "Epoch 26/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - loss: 0.2824 - val_loss: 0.8207\n",
      "Epoch 27/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 44ms/step - loss: 0.4992 - val_loss: 0.3698\n",
      "Epoch 28/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 43ms/step - loss: 0.3908 - val_loss: 0.3410\n",
      "Epoch 29/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 43ms/step - loss: 0.6586 - val_loss: 0.8761\n",
      "Epoch 30/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - loss: 0.4772 - val_loss: 0.5781\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras  # Import Keras from TensorFlow to build and train deep learning models\n",
    "\n",
    "# Enable eager execution in TensorFlow\n",
    "# Eager execution allows operations to be evaluated immediately as they are called within Python, \n",
    "# rather than being added to a computational graph to be run later. \n",
    "# This is required to use certain functionalities like the .numpy() method on tensors. \n",
    "# If eager execution is not enabled, TensorFlow throws an error when trying to access .numpy() on tensors.\n",
    "# This line ensures that eager execution is explicitly turned on, \n",
    "# even if it was disabled in some previous part of the code or environment.\n",
    "import tensorflow as tf\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "# Load an already trained Keras model from an HDF5 file named 'nonsequential_model.h5'\n",
    "# This file should contain the model architecture, weights, and optimizer state\n",
    "model = keras.models.load_model(\"nonsequential_model.h5\")\n",
    "\n",
    "# Recreate the optimizer\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, clipnorm=1.0)\n",
    "\n",
    "# Recompile the model with the new optimizer\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Create a TensorBoard callback instance\n",
    "# This will log training metrics such as loss and accuracy to the run_logdir directory\n",
    "# These logs can be visualized in TensorBoard for better insight into the model's training progress\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "# Train the loaded model on the training data for 30 epochs\n",
    "# - `X_train`, `y_train`: training features and targets\n",
    "# - `validation_data`: a tuple of validation features and targets to evaluate the model after each epoch\n",
    "# - `callbacks`: TensorBoard callback is passed to log training metrics\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4590d5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f2512cf3276abad9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f2512cf3276abad9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df5a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has not been written for running\n",
    "# It's a code for logging scalars, histograms, images, audio and text into TensorBoard\n",
    "import numpy as np\n",
    "\n",
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step/10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step/100 # Some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # Some random 32x32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"It's square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step= step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
