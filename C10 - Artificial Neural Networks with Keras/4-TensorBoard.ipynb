{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b7e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard is a powerful tool for visualizing and debugging machine learning models, \n",
    "# particularly in TensorFlow and Keras. It allows us to monitor key metrics, such as loss and accuracy,\n",
    "# track training progress in real-time, and analyze the performance of various model components \n",
    "# throughout the training process\n",
    "\n",
    "# Let's start by importing the California Housing dataset from Scikit-Learn\n",
    "from sklearn.datasets import fetch_california_housing  # Load the California housing dataset\n",
    "from sklearn.model_selection import train_test_split    # Tool to split data into train/validation/test sets\n",
    "from sklearn.preprocessing import StandardScaler        # Tool to scale features to standard normal distribution\n",
    "\n",
    "# Load the dataset (features and target)\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "\n",
    "# Further split training data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "# Standardize the features: zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)      # Fit on training data and transform it\n",
    "X_valid = scaler.transform(X_valid)          # Use the same transformation on validation data\n",
    "X_test = scaler.transform(X_test)            # Use the same transformation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940392d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system, specifically to create directories and handle paths.\n",
    "import os\n",
    "\n",
    "# Define the root directory where the log files will be stored.\n",
    "# 'os.curdir' represents the current working directory. 'my_logs' is the subdirectory where logs will be saved.\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "# Define a function to generate a unique directory path for each run.\n",
    "# This function creates a directory name based on the current date and time to ensure unique names for each experiment.\n",
    "def get_run_logdir():\n",
    "    # Import the time module to work with time-based information.\n",
    "    import time\n",
    "    \n",
    "    # Get the current time and format it as a string (e.g., 'run_2025_04_22-12_34_56').\n",
    "    # This helps in creating a unique run ID for every new experiment.\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    \n",
    "    # Return the full path to the log directory for the current run. This will be under the root_logdir.\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Call the get_run_logdir function to create the log directory path for the current run.\n",
    "# This will create a new subdirectory under 'my_logs' with a timestamped name.\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda85ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - loss: 0.5575 - val_loss: 3.6044\n",
      "Epoch 2/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - loss: 0.3752 - val_loss: 1.1019\n",
      "Epoch 3/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - loss: 0.3308 - val_loss: 1.0211\n",
      "Epoch 4/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 37ms/step - loss: 0.3358 - val_loss: 0.4029\n",
      "Epoch 5/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - loss: 0.3247 - val_loss: 0.3516\n",
      "Epoch 6/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - loss: 0.3269 - val_loss: 0.8427\n",
      "Epoch 7/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - loss: 0.3190 - val_loss: 0.5300\n",
      "Epoch 8/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 37ms/step - loss: 0.3211 - val_loss: 0.3278\n",
      "Epoch 9/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - loss: 0.3216 - val_loss: 0.4668\n",
      "Epoch 10/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.3315 - val_loss: 1.3151\n",
      "Epoch 11/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - loss: 0.3041 - val_loss: 0.8683\n",
      "Epoch 12/30\n",
      "\u001b[1m 27/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - loss: 0.4006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_12624\\2519945182.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Train the loaded model on the training data for 30 epochs\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# - `X_train`, `y_train`: training features and targets\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# - `validation_data`: a tuple of validation features and targets to evaluate the model after each epoch\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# - `callbacks`: TensorBoard callback is passed to log training metrics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m history = model.fit(X_train, y_train, epochs=30,\n\u001b[32m     33\u001b[39m                     validation_data=(X_valid, y_valid),\n\u001b[32m     34\u001b[39m                     callbacks=[tensorboard_cb])\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    367\u001b[39m             callbacks.on_epoch_begin(epoch)\n\u001b[32m    368\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m    369\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;28;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m                     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m                     logs = self.train_function(iterator)\n\u001b[32m    372\u001b[39m                     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m self.stop_training:\n\u001b[32m    374\u001b[39m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m function(iterator):\n\u001b[32m    216\u001b[39m             if isinstance(\n\u001b[32m    217\u001b[39m                 iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m             ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m                 opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m    220\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m StopIteration\n\u001b[32m    222\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    806\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwds):\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Implements PolymorphicFunction.__call__.\u001b[39;00m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m self._run_functions_eagerly:\n\u001b[32m    809\u001b[39m       \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(self._name, tf_function_call=\u001b[33m\"eager\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._python_function(*args, **kwds)\n\u001b[32m    811\u001b[39m \n\u001b[32m    812\u001b[39m     \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[32m    813\u001b[39m     \u001b[38;5;66;03m# place.\u001b[39;00m\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    128\u001b[39m         @tf.autograph.experimental.do_not_convert\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m multi_step_on_iterator(iterator):\n\u001b[32m    130\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m    131\u001b[39m                 return tf.experimental.Optional.from_value(\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m                     one_step_on_data(iterator.get_next())\n\u001b[32m    133\u001b[39m                 )\n\u001b[32m    134\u001b[39m \n\u001b[32m    135\u001b[39m             \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    806\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwds):\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Implements PolymorphicFunction.__call__.\u001b[39;00m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m self._run_functions_eagerly:\n\u001b[32m    809\u001b[39m       \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(self._name, tf_function_call=\u001b[33m\"eager\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._python_function(*args, **kwds)\n\u001b[32m    811\u001b[39m \n\u001b[32m    812\u001b[39m     \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[32m    813\u001b[39m     \u001b[38;5;66;03m# place.\u001b[39;00m\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    110\u001b[39m         @tf.autograph.experimental.do_not_convert\n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m one_step_on_data(data):\n\u001b[32m    112\u001b[39m             \u001b[33m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m             outputs = self.distribute_strategy.run(step_function, args=(data,))\n\u001b[32m    114\u001b[39m             outputs = reduce_per_replica(\n\u001b[32m    115\u001b[39m                 outputs,\n\u001b[32m    116\u001b[39m                 self.distribute_strategy,\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1669\u001b[39m       \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[32m   1670\u001b[39m       \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[32m   1671\u001b[39m       fn = autograph.tf_convert(\n\u001b[32m   1672\u001b[39m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   3259\u001b[39m     _require_cross_replica_or_default_context_extended(self)\n\u001b[32m   3260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3261\u001b[39m       kwargs = {}\n\u001b[32m   3262\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m self._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m self._call_for_each_replica(fn, args, kwargs)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   4059\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m _call_for_each_replica(self, fn, args, kwargs):\n\u001b[32m   4060\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(self._container_strategy(), replica_id_in_sync_group=\u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4061\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     76\u001b[39m             trainable_weights = self.trainable_weights\n\u001b[32m     77\u001b[39m             gradients = tape.gradient(loss, trainable_weights)\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m             \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m             self.optimizer.apply_gradients(zip(gradients, trainable_weights))\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m             warnings.warn(\u001b[33m\"The model does not have any trainable weights.\"\u001b[39m)\n\u001b[32m     83\u001b[39m \n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads_and_vars)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m apply_gradients(self, grads_and_vars):\n\u001b[32m    382\u001b[39m         grads, trainable_variables = zip(*grads_and_vars)\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m         self.apply(grads, trainable_variables)\n\u001b[32m    384\u001b[39m         \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[32m    385\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._iterations\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    444\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    445\u001b[39m                 grads = [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g / scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;28;01min\u001b[39;00m grads]\n\u001b[32m    446\u001b[39m \n\u001b[32m    447\u001b[39m             \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m             self._backend_apply_gradients(grads, trainable_variables)\n\u001b[32m    449\u001b[39m             \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[32m    450\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;28;01min\u001b[39;00m trainable_variables:\n\u001b[32m    451\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m variable.constraint \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    507\u001b[39m             grads = self._clip_gradients(grads)\n\u001b[32m    508\u001b[39m             self._apply_weight_decay(trainable_variables)\n\u001b[32m    509\u001b[39m \n\u001b[32m    510\u001b[39m             \u001b[38;5;66;03m# Run update step.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m             self._backend_update_step(\n\u001b[32m    512\u001b[39m                 grads, trainable_variables, self.learning_rate\n\u001b[32m    513\u001b[39m             )\n\u001b[32m    514\u001b[39m \n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads, trainable_variables, learning_rate)\u001b[39m\n\u001b[32m    115\u001b[39m             v.value \u001b[38;5;28;01mif\u001b[39;00m isinstance(v, backend.Variable) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[32m    116\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;28;01min\u001b[39;00m trainable_variables\n\u001b[32m    117\u001b[39m         ]\n\u001b[32m    118\u001b[39m         grads_and_vars = list(zip(grads, trainable_variables))\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m         grads_and_vars = self._all_reduce_sum_gradients(grads_and_vars)\n\u001b[32m    120\u001b[39m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[32m    121\u001b[39m             self._distributed_tf_update_step,\n\u001b[32m    122\u001b[39m             self._distribution_strategy,\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads_and_vars)\u001b[39m\n\u001b[32m    155\u001b[39m         grads_and_vars = list(grads_and_vars)\n\u001b[32m    156\u001b[39m         filtered_grads_and_vars = filter_empty_gradients(grads_and_vars)\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filtered_grads_and_vars:\n\u001b[32m    158\u001b[39m             grads = [pair[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;28;01min\u001b[39;00m filtered_grads_and_vars]\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m             reduced = tf.distribute.get_replica_context().all_reduce(\n\u001b[32m    160\u001b[39m                 tf.distribute.ReduceOp.SUM, grads\n\u001b[32m    161\u001b[39m             )\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, reduce_op, value, options)\u001b[39m\n\u001b[32m   3637\u001b[39m       \u001b[38;5;28;01mdef\u001b[39;00m grad_wrapper(*xs):\n\u001b[32m   3638\u001b[39m         ys = self.merge_call(batch_all_reduce, args=xs)\n\u001b[32m   3639\u001b[39m         \u001b[38;5;66;03m# The gradient of an all-sum is itself an all-sum (all-mean, likewise).\u001b[39;00m\n\u001b[32m   3640\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m ys, \u001b[38;5;28;01mlambda\u001b[39;00m *dy_s: self.all_reduce(reduce_op, dy_s)\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m nest.pack_sequence_as(value, grad_wrapper(*flattened_value))\n\u001b[32m   3642\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3643\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m has_indexed_slices:\n\u001b[32m   3644\u001b[39m         return nest.pack_sequence_as(\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\custom_gradient.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *a, **k)\u001b[39m\n\u001b[32m    338\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *a, **k):\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m self._d(self._f, a, k)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\custom_gradient.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(wrapped, args, kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m   @Bind.decorator\n\u001b[32m    290\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m decorated(wrapped, args, kwargs):\n\u001b[32m    291\u001b[39m     \u001b[33m\"\"\"Decorated function with custom gradient.\"\"\"\u001b[39m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _eager_mode_decorator(wrapped, args, kwargs)\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    295\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _graph_mode_decorator(wrapped, args, kwargs)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\custom_gradient.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(f, args, kwargs)\u001b[39m\n\u001b[32m    558\u001b[39m         \"since function uses variables: {}\".format(variables))\n\u001b[32m    559\u001b[39m   flat_result = composite_tensor_gradient.get_flat_tensors_for_gradients(\n\u001b[32m    560\u001b[39m       nest.flatten(result))\n\u001b[32m    561\u001b[39m   \u001b[38;5;66;03m# TODO(apassos) consider removing the identity below.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m   flat_result = [gen_array_ops.identity(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m flat_result]\n\u001b[32m    563\u001b[39m \n\u001b[32m    564\u001b[39m   input_tensors = [\n\u001b[32m    565\u001b[39m       ops.convert_to_tensor(x) for x in flat_args + list(variables)]\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\custom_gradient.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m _eager_mode_decorator(f, args, kwargs):\n\u001b[32m    563\u001b[39m   \u001b[33m\"\"\"Implement custom gradient decorator for eager mode.\"\"\"\u001b[39m\n\u001b[32m    564\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m record.VariableWatcher() \u001b[38;5;28;01mas\u001b[39;00m variable_watcher:\n\u001b[32m    565\u001b[39m     result, grad_fn = f(*args, **kwargs)\n",
      "\u001b[32md:\\hands_on_machine_learning\\C10 - Artificial Neural Networks with Keras\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input, name)\u001b[39m\n\u001b[32m   4227\u001b[39m         _ctx, \"Identity\", name, input)\n\u001b[32m   4228\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   4229\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   4230\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m4231\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   4232\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   4233\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4234\u001b[39m       return identity_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras  # Import Keras from TensorFlow to build and train deep learning models\n",
    "\n",
    "# Enable eager execution in TensorFlow\n",
    "# Eager execution allows operations to be evaluated immediately as they are called within Python, \n",
    "# rather than being added to a computational graph to be run later. \n",
    "# This is required to use certain functionalities like the .numpy() method on tensors. \n",
    "# If eager execution is not enabled, TensorFlow throws an error when trying to access .numpy() on tensors.\n",
    "# This line ensures that eager execution is explicitly turned on, \n",
    "# even if it was disabled in some previous part of the code or environment.\n",
    "import tensorflow as tf\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "# Load an already trained Keras model from an HDF5 file named 'nonsequential_model.h5'\n",
    "# This file should contain the model architecture, weights, and optimizer state\n",
    "model = keras.models.load_model(\"nonsequential_model.h5\")\n",
    "\n",
    "# Recreate the optimizer\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.0)\n",
    "\n",
    "# Recompile the model with the new optimizer\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Create a TensorBoard callback instance\n",
    "# This will log training metrics such as loss and accuracy to the run_logdir directory\n",
    "# These logs can be visualized in TensorBoard for better insight into the model's training progress\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "# Train the loaded model on the training data for 30 epochs\n",
    "# - `X_train`, `y_train`: training features and targets\n",
    "# - `validation_data`: a tuple of validation features and targets to evaluate the model after each epoch\n",
    "# - `callbacks`: TensorBoard callback is passed to log training metrics\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has not been written for running\n",
    "# It's a code for logging scalars, histograms, images, audio and text into TensorBoard\n",
    "\n",
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step/10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step/100 # Some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # Some random 32x32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"It's square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step= step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
